{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9448609,"sourceType":"datasetVersion","datasetId":5742831},{"sourceId":9448677,"sourceType":"datasetVersion","datasetId":5742878},{"sourceId":9449026,"sourceType":"datasetVersion","datasetId":5743137}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installations","metadata":{}},{"cell_type":"code","source":"!pip -q install torch\n!pip -q install torchvision\n!pip -q install albumentations\n!pip -q install onnx\n!pip -q install opencv-python\n!pip -q install pynvml\n!pip -q install nvidia-pyindex\n!pip -q install nvidia-tensorrt==8.4.3.1\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:44:35.349198Z","iopub.execute_input":"2024-10-03T13:44:35.349603Z","iopub.status.idle":"2024-10-03T13:46:12.105273Z","shell.execute_reply.started":"2024-10-03T13:44:35.349564Z","shell.execute_reply":"2024-10-03T13:46:12.103909Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Resnet Model Conversion to ONNX","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport torch\nfrom torchvision import models\n\n# Load pretrained ResNet50 model\nmodel = models.resnet50(pretrained=True)\nmodel.eval()\n\n# Dummy input for the ONNX export\ndummy_input = torch.randn(1, 3, 224, 224)  # Batch size of 1, 3 color channels, 224x224 resolution\n\n# Convert to ONNX format\nONNX_FILE_PATH = 'resnet50.onnx'\ntorch.onnx.export(model, dummy_input, ONNX_FILE_PATH, input_names=['input'], output_names=['output'], export_params=True)\n\nprint(f\"Model successfully converted to {ONNX_FILE_PATH}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:46:12.107936Z","iopub.execute_input":"2024-10-03T13:46:12.108404Z","iopub.status.idle":"2024-10-03T13:46:14.133771Z","shell.execute_reply.started":"2024-10-03T13:46:12.108358Z","shell.execute_reply":"2024-10-03T13:46:14.132755Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Model successfully converted to resnet50.onnx\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Building The Engine\n","metadata":{}},{"cell_type":"code","source":"import tensorrt as trt\nimport os\n\n\nwarnings.filterwarnings(\"ignore\")\n\ndef build_engine_from_onnx(onnx_file_path, engine_file_path, max_batch_size=1, fp16_mode=False, int8_mode=False):\n    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n    EXPLICIT_BATCH = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n    \n    with trt.Builder(TRT_LOGGER) as builder, \\\n         builder.create_network(EXPLICIT_BATCH) as network, \\\n         trt.OnnxParser(network, TRT_LOGGER) as parser:\n        \n        config = builder.create_builder_config()\n        config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)  # 1GB\n        if fp16_mode:\n            config.set_flag(trt.BuilderFlag.FP16)\n        if int8_mode:\n            config.set_flag(trt.BuilderFlag.INT8)\n        \n        # Parse ONNX\n        with open(onnx_file_path, 'rb') as model:\n            if not parser.parse(model.read()):\n                print('ERROR: Failed to parse the ONNX file.')\n                for error in range(parser.num_errors):\n                    print(parser.get_error(error))\n                return None\n        \n        profile = builder.create_optimization_profile()\n        input_name = network.get_input(0).name\n        input_shape = network.get_input(0).shape\n        profile.set_shape(input_name, (1, *input_shape[1:]), (max_batch_size, *input_shape[1:]), (max_batch_size, *input_shape[1:]))\n        config.add_optimization_profile(profile)\n        \n        print('Building an engine from file {}; this may take a while...'.format(onnx_file_path))\n        serialized_engine = builder.build_serialized_network(network, config)\n        print(\"Completed creating engine\")\n        \n        with open(engine_file_path, \"wb\") as f:\n            f.write(serialized_engine)\n        \n        return serialized_engine\nprint(\"Engine has been Builded\")","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:46:54.960924Z","iopub.execute_input":"2024-10-03T13:46:54.961612Z","iopub.status.idle":"2024-10-03T13:46:54.973421Z","shell.execute_reply.started":"2024-10-03T13:46:54.961571Z","shell.execute_reply":"2024-10-03T13:46:54.972513Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Engine has been Builded\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Loading the Engine","metadata":{}},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")\ndef load_engine(engine_file_path):\n    with open(engine_file_path, 'rb') as f, trt.Runtime(trt.Logger(trt.Logger.WARNING)) as runtime:\n        return runtime.deserialize_cuda_engine(f.read())\n\nonnx_file_path = \"/kaggle/working/resnet50.onnx\"\nengine_file_path = \"resnet50.engine\"\n\n# Convert ONNX to TensorRT engine if it doesn't exist\nif not os.path.exists(engine_file_path):\n    serialized_engine = build_engine_from_onnx(onnx_file_path, engine_file_path)\n    with trt.Runtime(trt.Logger(trt.Logger.WARNING)) as runtime:\n        engine = runtime.deserialize_cuda_engine(serialized_engine)\nelse:\n    # Load the existing engine\n    engine = load_engine(engine_file_path)\n\n# Create execution context\ncontext = engine.create_execution_context()\n\nprint(\"TensorRT engine loaded and execution context created successfully.\")","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:47:14.457028Z","iopub.execute_input":"2024-10-03T13:47:14.457926Z","iopub.status.idle":"2024-10-03T13:47:14.564296Z","shell.execute_reply.started":"2024-10-03T13:47:14.457885Z","shell.execute_reply":"2024-10-03T13:47:14.563351Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"[10/03/2024-13:47:14] [TRT] [W] TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.4.0\nTensorRT engine loaded and execution context created successfully.\n[10/03/2024-13:47:14] [TRT] [W] TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.4.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Helper Functions","metadata":{}},{"cell_type":"code","source":"def preprocess_image(image_path, img_size=(224, 224)):\n    input_image = Image.open(image_path).convert(\"RGB\")\n    preprocess = transforms.Compose([\n        transforms.Resize(img_size),\n        transforms.CenterCrop(img_size),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n    input_tensor = preprocess(input_image)\n    input_batch = input_tensor.unsqueeze(0)  # create a mini-batch as expected by the model\n    return input_batch\n\n\n# Function to load images from folder\ndef load_images_from_folder(folder_path):\n    image_paths = []\n    for filename in os.listdir(folder_path):\n        if filename.endswith('.jpg') or filename.endswith('.png'):\n            image_paths.append(os.path.join(folder_path, filename))\n    return image_paths","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:47:38.785734Z","iopub.execute_input":"2024-10-03T13:47:38.786128Z","iopub.status.idle":"2024-10-03T13:47:38.795269Z","shell.execute_reply.started":"2024-10-03T13:47:38.786089Z","shell.execute_reply":"2024-10-03T13:47:38.794166Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# General Comparsion for 100 Images","metadata":{}},{"cell_type":"code","source":"import os\nimport tensorrt as trt\nimport torch\nimport time\nimport pycuda.driver as cuda\nimport pycuda.autoinit\nfrom pynvml import nvmlInit, nvmlShutdown, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo\nimport numpy as np\nfrom PIL import Image\nfrom torchvision import transforms\nfrom statistics import mean, stdev\n\n# Initialize the NVML library\nnvmlInit()\n\nwarnings.filterwarnings(\"ignore\")\n\n\n\ndef benchmark_pytorch_model(model, images, preprocess_image):\n    total_time = 0\n    inference_times = []\n    \n    for img_path in images:\n        input_tensor = preprocess_image(img_path).cuda()\n        torch.cuda.synchronize()  # Synchronize GPU before timing\n        start_time = time.time()\n        \n        with torch.no_grad():\n            model(input_tensor)  # Perform inference\n        \n        torch.cuda.synchronize()  # Synchronize again after inference\n        end_time = time.time()\n        \n        inference_time = end_time - start_time\n        total_time += inference_time\n        inference_times.append(inference_time)\n        \n        gpu_used, _, _ = get_gpu_metrics()\n        print(f\"Image: {img_path}, Inference time (PyTorch): {inference_time:.4f} s, GPU used: {gpu_used:.2f} MB\")\n    \n    return total_time, inference_times\n\n\ndef benchmark_tensorrt_model(context, engine, images, bindings, stream, input_shape, preprocess_image):\n    total_time = 0\n    inference_times = []\n    \n    for img_path in images:\n        input_tensor = preprocess_image(img_path).cpu().numpy()\n\n        # Handle dynamic input shape\n        if engine.has_implicit_batch_dimension:\n            context.set_binding_shape(0, input_tensor.shape)\n        else:\n            context.set_binding_shape(0, (1, *input_tensor.shape[1:]))\n\n        # Ensure input matches expected shape\n        if input_tensor.shape != tuple(input_shape):\n            input_tensor = input_tensor.reshape(input_shape)\n\n        # Copy input data to GPU memory\n        cuda.memcpy_htod_async(bindings[0], input_tensor, stream)\n\n        # Allocate output memory\n        output = cuda.pagelocked_empty(tuple(context.get_binding_shape(1)), dtype=np.float32)\n        output_memory = cuda.mem_alloc(output.nbytes)\n        bindings[1] = int(output_memory)\n\n        # Measure inference time\n        stream.synchronize()\n        start_time = time.time()\n        context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n        stream.synchronize()\n        end_time = time.time()\n\n        # Copy output data from GPU memory\n        cuda.memcpy_dtoh_async(output, output_memory, stream)\n        stream.synchronize()\n\n        # Free the output memory\n        output_memory.free()\n\n        # Calculate inference time and GPU memory usage\n        inference_time = end_time - start_time\n        total_time += inference_time\n        inference_times.append(inference_time)\n        \n        gpu_used, _, _ = get_gpu_metrics()\n        print(f\"Image: {img_path}, Inference time (TensorRT): {inference_time:.4f} s, GPU used: {gpu_used:.2f} MB\")\n    \n    return total_time, inference_times\n\n\ndef print_inference_stats(times, model_name):\n    print(f\"--- {model_name} Inference Time Statistics ---\")\n    print(f\"Average Inference Time: {mean(times):.4f} s\")\n    print(f\"Standard Deviation: {stdev(times):.4f} s\")\n    print(f\"Min Inference Time: {min(times):.4f} s\")\n    print(f\"Max Inference Time: {max(times):.4f} s\")\n    print()\n\ndef compare_models(times_pytorch, times_tensorrt):\n    avg_pytorch = mean(times_pytorch)\n    avg_tensorrt = mean(times_tensorrt)\n\n    speedup_factor = avg_pytorch / avg_tensorrt\n    percentage_faster = (speedup_factor - 1) * 100\n\n    print(\"Comparison between PyTorch and TensorRT:\")\n    print(f\"Average PyTorch Inference Time: {avg_pytorch:.4f} s\")\n    print(f\"Average TensorRT Inference Time: {avg_tensorrt:.4f} s\")\n    print(f\"TensorRT is {speedup_factor:.2f}x faster than PyTorch.\")\n    print()\n\n\n# Main execution\nif __name__ == \"__main__\":\n    onnx_file_path = \"/kaggle/working/resnet50.onnx\"\n    engine_file_path = \"resnet50.engine\"\n    \n    print(f\"TensorRT version: {trt.__version__}\")\n    \n    # Convert ONNX to TensorRT engine if it doesn't exist\n    if not os.path.exists(engine_file_path):\n        print(f\"Building TensorRT engine from {onnx_file_path}\")\n        engine = build_engine_from_onnx(onnx_file_path, engine_file_path)\n    else:\n        print(f\"Loading existing TensorRT engine from {engine_file_path}\")\n        engine = load_engine(engine_file_path)\n    \n    # Create execution context\n    context = engine.create_execution_context()\n    print(\"----------------TensorRT engine loaded and execution context created successfully.-----------\")\n    \n    if os.path.exists(engine_file_path):\n        print(f\"Confirmed: TensorRT engine file saved at {engine_file_path}\")\n        print(f\"File size: {os.path.getsize(engine_file_path) / (1024 * 1024):.2f} MB\")\n    else:\n        print(f\"Warning: Expected engine file {engine_file_path} not found!\")\n\n    # Set up GPU memory for input and output\n    input_shape = context.get_binding_shape(0)\n    output_shape = context.get_binding_shape(1)\n    print(f\"Input tensor shape: {input_shape}\")\n    print(f\"Output tensor shape: {output_shape}\")\n\n    # Allocate device memory\n    d_input = cuda.mem_alloc(trt.volume(input_shape) * trt.float32.itemsize)\n    d_output = cuda.mem_alloc(trt.volume(output_shape) * trt.float32.itemsize)\n    bindings = [int(d_input), int(d_output)]\n    stream = cuda.Stream()\n\n    # Load images for benchmarking\n    image_folder = \"/kaggle/input/dataset/images\"  # Replace with your image folder path\n    images = load_images_from_folder(image_folder)\n\n    # Load the PyTorch ResNet50 model for benchmarking\n    pytorch_model = torch.hub.load('pytorch/vision', 'resnet50', pretrained=True).eval().cuda()\n\n    # Benchmark PyTorch model\n    print(\"Running benchmark for PyTorch ResNet50 model...\")\n    total_time_pytorch, inference_times_pytorch = benchmark_pytorch_model(pytorch_model, images, preprocess_image)\n\n    # Benchmark TensorRT model\n    print(\"Running benchmark for TensorRT ResNet50 model...\")\n    total_time_trt, inference_times_trt = benchmark_tensorrt_model(context, engine, images, bindings, stream, input_shape, preprocess_image)\n\n    # Print statistics\n    print_inference_stats(inference_times_pytorch, \"PyTorch\")\n    print_inference_stats(inference_times_trt, \"TensorRT\")\n    \n    compare_models(inference_times_pytorch, inference_times_trt)\n    \n    \n    d_input.free()\n    d_output.free()\n    nvmlShutdown()  \n","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:53:22.935837Z","iopub.execute_input":"2024-10-03T13:53:22.936246Z","iopub.status.idle":"2024-10-03T13:53:25.852009Z","shell.execute_reply.started":"2024-10-03T13:53:22.936212Z","shell.execute_reply":"2024-10-03T13:53:25.850266Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"TensorRT version: 8.4.3.1\nLoading existing TensorRT engine from resnet50.engine\n[10/03/2024-13:53:23] [TRT] [W] TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.4.0\n----------------TensorRT engine loaded and execution context created successfully.-----------\nConfirmed: TensorRT engine file saved at resnet50.engine\nFile size: 99.47 MB\nInput tensor shape: (1, 3, 224, 224)\nOutput tensor shape: (1, 1000)\n[10/03/2024-13:53:23] [TRT] [W] TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.4.0\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/pytorch_vision_main\n","output_type":"stream"},{"name":"stdout","text":"Running benchmark for PyTorch ResNet50 model...\nImage: /kaggle/input/dataset/images/image27.jpg, Inference time (PyTorch): 0.0089 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2542.jpg, Inference time (PyTorch): 0.0085 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2621.jpg, Inference time (PyTorch): 0.0088 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image56.jpg, Inference time (PyTorch): 0.0083 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2.jpg, Inference time (PyTorch): 0.0085 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2572.jpg, Inference time (PyTorch): 0.0086 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image47.jpg, Inference time (PyTorch): 0.0084 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image40.jpg, Inference time (PyTorch): 0.0085 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image34.jpg, Inference time (PyTorch): 0.0084 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image36.jpg, Inference time (PyTorch): 0.0099 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2615.jpg, Inference time (PyTorch): 0.0084 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image65.jpg, Inference time (PyTorch): 0.0084 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image42.jpg, Inference time (PyTorch): 0.0084 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2528.jpg, Inference time (PyTorch): 0.0085 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image62.jpg, Inference time (PyTorch): 0.0085 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image46.jpg, Inference time (PyTorch): 0.0083 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2616.jpg, Inference time (PyTorch): 0.0084 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2561.jpg, Inference time (PyTorch): 0.0076 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image43.jpg, Inference time (PyTorch): 0.0075 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image39.jpg, Inference time (PyTorch): 0.0076 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image74.jpg, Inference time (PyTorch): 0.0076 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2576.jpg, Inference time (PyTorch): 0.0086 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2614.jpg, Inference time (PyTorch): 0.0081 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image75.jpg, Inference time (PyTorch): 0.0081 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2519.jpg, Inference time (PyTorch): 0.0079 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image25.jpg, Inference time (PyTorch): 0.0077 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2545.jpg, Inference time (PyTorch): 0.0077 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2530.jpg, Inference time (PyTorch): 0.0075 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2562.jpg, Inference time (PyTorch): 0.0078 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2541.jpg, Inference time (PyTorch): 0.0074 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image54.jpg, Inference time (PyTorch): 0.0075 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image26.jpg, Inference time (PyTorch): 0.0077 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2552.jpg, Inference time (PyTorch): 0.0076 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image1.jpg, Inference time (PyTorch): 0.0075 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2560.jpg, Inference time (PyTorch): 0.0074 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image17.jpg, Inference time (PyTorch): 0.0089 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image11.jpg, Inference time (PyTorch): 0.0074 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image12.jpg, Inference time (PyTorch): 0.0071 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image69.jpg, Inference time (PyTorch): 0.0070 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image3.jpg, Inference time (PyTorch): 0.0074 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image20.jpg, Inference time (PyTorch): 0.0078 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image48.jpg, Inference time (PyTorch): 0.0080 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image44.jpg, Inference time (PyTorch): 0.0080 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image57.jpg, Inference time (PyTorch): 0.0078 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image6.jpg, Inference time (PyTorch): 0.0077 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2630.jpg, Inference time (PyTorch): 0.0078 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image14.jpg, Inference time (PyTorch): 0.0081 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image87.jpg, Inference time (PyTorch): 0.0078 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image86.jpg, Inference time (PyTorch): 0.0078 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image45.jpg, Inference time (PyTorch): 0.0078 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image37.jpg, Inference time (PyTorch): 0.0079 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image21.jpg, Inference time (PyTorch): 0.0080 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image59.jpg, Inference time (PyTorch): 0.0077 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image31.jpg, Inference time (PyTorch): 0.0076 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image64.jpg, Inference time (PyTorch): 0.0099 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image15.jpg, Inference time (PyTorch): 0.0080 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image22.jpg, Inference time (PyTorch): 0.0074 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image30.jpg, Inference time (PyTorch): 0.0070 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image55.jpg, Inference time (PyTorch): 0.0069 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image82.jpg, Inference time (PyTorch): 0.0070 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image60.jpg, Inference time (PyTorch): 0.0071 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2624.jpg, Inference time (PyTorch): 0.0071 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image23.jpg, Inference time (PyTorch): 0.0071 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2540.jpg, Inference time (PyTorch): 0.0072 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image4.jpg, Inference time (PyTorch): 0.0071 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2515.jpg, Inference time (PyTorch): 0.0076 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image9.jpg, Inference time (PyTorch): 0.0072 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2564.jpg, Inference time (PyTorch): 0.0073 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image29.jpg, Inference time (PyTorch): 0.0072 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image8.jpg, Inference time (PyTorch): 0.0075 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image52.jpg, Inference time (PyTorch): 0.0079 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image49.jpg, Inference time (PyTorch): 0.0074 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image32.jpg, Inference time (PyTorch): 0.0073 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image66.jpg, Inference time (PyTorch): 0.0075 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2548.jpg, Inference time (PyTorch): 0.0093 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2619.jpg, Inference time (PyTorch): 0.0070 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image61.jpg, Inference time (PyTorch): 0.0075 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image18.jpg, Inference time (PyTorch): 0.0080 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2566.jpg, Inference time (PyTorch): 0.0079 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2513.jpg, Inference time (PyTorch): 0.0080 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2620.jpg, Inference time (PyTorch): 0.0079 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image5.jpg, Inference time (PyTorch): 0.0079 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image41.jpg, Inference time (PyTorch): 0.0079 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image10.jpg, Inference time (PyTorch): 0.0079 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image16.jpg, Inference time (PyTorch): 0.0080 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2628.jpg, Inference time (PyTorch): 0.0079 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image53.jpg, Inference time (PyTorch): 0.0077 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image28.jpg, Inference time (PyTorch): 0.0076 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image35.jpg, Inference time (PyTorch): 0.0076 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image51.jpg, Inference time (PyTorch): 0.0078 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2532.jpg, Inference time (PyTorch): 0.0076 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image13.jpg, Inference time (PyTorch): 0.0076 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2571.jpg, Inference time (PyTorch): 0.0077 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image19.jpg, Inference time (PyTorch): 0.0086 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image7.jpg, Inference time (PyTorch): 0.0075 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image24.jpg, Inference time (PyTorch): 0.0076 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image50.jpg, Inference time (PyTorch): 0.0073 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image33.jpg, Inference time (PyTorch): 0.0075 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image38.jpg, Inference time (PyTorch): 0.0072 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2573.jpg, Inference time (PyTorch): 0.0077 s, GPU used: 2897.88 MB\nRunning benchmark for TensorRT ResNet50 model...\nImage: /kaggle/input/dataset/images/image27.jpg, Inference time (TensorRT): 0.0034 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2542.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2621.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image56.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2572.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image47.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image40.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image34.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image36.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2615.jpg, Inference time (TensorRT): 0.0031 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image65.jpg, Inference time (TensorRT): 0.0031 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image42.jpg, Inference time (TensorRT): 0.0031 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2528.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image62.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image46.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2616.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2561.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image43.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image39.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image74.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2576.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2614.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image75.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2519.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image25.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2545.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2530.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2562.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2541.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image54.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image26.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2552.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image1.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2560.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image17.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image11.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image12.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image69.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image3.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image20.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image48.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image44.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image57.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image6.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2630.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image14.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image87.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image86.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image45.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image37.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image21.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image59.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image31.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image64.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image15.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image22.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image30.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image55.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image82.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image60.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2624.jpg, Inference time (TensorRT): 0.0058 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image23.jpg, Inference time (TensorRT): 0.0031 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2540.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image4.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2515.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image9.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2564.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image29.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image8.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image52.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image49.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image32.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image66.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2548.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2619.jpg, Inference time (TensorRT): 0.0030 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image61.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image18.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2566.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2513.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2620.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image5.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image41.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image10.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image16.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2628.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image53.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image28.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image35.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image51.jpg, Inference time (TensorRT): 0.0036 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2532.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image13.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2571.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image19.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image7.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image24.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image50.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image33.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image38.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\nImage: /kaggle/input/dataset/images/image2573.jpg, Inference time (TensorRT): 0.0029 s, GPU used: 2897.88 MB\n--- PyTorch Inference Time Statistics ---\nAverage Inference Time: 0.0078 s\nStandard Deviation: 0.0006 s\nMin Inference Time: 0.0069 s\nMax Inference Time: 0.0099 s\n\n--- TensorRT Inference Time Statistics ---\nAverage Inference Time: 0.0030 s\nStandard Deviation: 0.0003 s\nMin Inference Time: 0.0029 s\nMax Inference Time: 0.0058 s\n\nComparison between PyTorch and TensorRT:\nAverage PyTorch Inference Time: 0.0078 s\nAverage TensorRT Inference Time: 0.0030 s\nTensorRT is 2.62x faster than PyTorch.\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Playing with batch size, Precision(INT8, FP16) and Image size","metadata":{}},{"cell_type":"code","source":"# Initialize NVML for GPU memory metrics\nnvmlInit()\n\ndef get_gpu_metrics(device_index=0):\n    nvml_device = nvmlDeviceGetHandleByIndex(device_index)\n    memory_info = nvmlDeviceGetMemoryInfo(nvml_device)\n    gpu_usage = memory_info.used / (1024 ** 2)  # Convert to MB\n    return gpu_usage, memory_info.free / (1024 ** 2), memory_info.total / (1024 ** 2)\n\n\ndef preprocess_image(image_path, img_size):\n    input_image = Image.open(image_path).convert(\"RGB\")\n    preprocess = transforms.Compose([\n        transforms.Resize(img_size),\n        transforms.CenterCrop(img_size),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n    input_tensor = preprocess(input_image)\n    return input_tensor\n\ndef load_images_from_folder(folder_path):\n    image_paths = []\n    for filename in os.listdir(folder_path):\n        if filename.endswith('.jpg') or filename.endswith('.png'):\n            image_paths.append(os.path.join(folder_path, filename))\n    return image_paths\n\ndef benchmark_pytorch_model(model, images, preprocess_image, batch_size, img_size):\n    total_time = 0\n    inference_times = []\n\n    for i in range(0, len(images), batch_size):\n        batch_images = images[i:i+batch_size]\n        input_batch = torch.stack([preprocess_image(img_path, img_size) for img_path in batch_images]).cuda()\n\n        torch.cuda.synchronize()\n        start_time = time.time()\n\n        with torch.no_grad():\n            model(input_batch)\n\n        torch.cuda.synchronize()\n        end_time = time.time()\n\n        inference_time = end_time - start_time\n        total_time += inference_time\n        inference_times.append(inference_time)\n\n        gpu_used, _, _ = get_gpu_metrics()\n        print(f\"Batch {i//batch_size + 1}, Inference time (PyTorch): {inference_time:.4f} s, GPU used: {gpu_used:.2f} MB\")\n\n    return total_time, inference_times\n\ndef benchmark_tensorrt_model(context, engine, images, bindings, stream, input_shape, preprocess_image, batch_size, img_size):\n    total_time = 0\n    inference_times = []\n\n    for i in range(0, len(images), batch_size):\n        batch_images = images[i:i+batch_size]\n        input_batch = np.stack([preprocess_image(img_path, img_size).numpy() for img_path in batch_images])\n\n        if engine.has_implicit_batch_dimension:\n            context.set_binding_shape(0, input_batch.shape)\n        else:\n            context.set_binding_shape(0, (batch_size, *input_shape[1:]))\n\n        # Allocate device memory\n        d_input = cuda.mem_alloc(input_batch.nbytes)\n        d_output = cuda.mem_alloc(trt.volume(context.get_binding_shape(1)) * trt.float32.itemsize)\n        bindings = [int(d_input), int(d_output)]\n\n        # Copy input data to device\n        cuda.memcpy_htod_async(d_input, input_batch, stream)\n\n        # Run inference\n        stream.synchronize()\n        start_time = time.time()\n        context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n        stream.synchronize()\n        end_time = time.time()\n\n        inference_time = end_time - start_time\n        total_time += inference_time\n        inference_times.append(inference_time)\n\n        gpu_used, _, _ = get_gpu_metrics()\n        print(f\"Batch {i//batch_size + 1}, Inference time (TensorRT): {inference_time:.4f} s, GPU used: {gpu_used:.2f} MB\")\n\n        # Free device memory\n        d_input.free()\n        d_output.free()\n\n    return total_time, inference_times\n\ndef print_inference_stats(times, model_name):\n    print(f\"--- {model_name} Inference Time Statistics ---\")\n    print(f\"Average Inference Time: {mean(times):.4f} s\")\n    print(f\"Standard Deviation: {stdev(times):.4f} s\")\n    print(f\"Min Inference Time: {min(times):.4f} s\")\n    print(f\"Max Inference Time: {max(times):.4f} s\")\n    print()\n\ndef compare_models(times_pytorch, times_tensorrt, precision, batch_size):\n    avg_pytorch = mean(times_pytorch)\n    avg_tensorrt = mean(times_tensorrt)\n\n    speedup_factor = avg_pytorch / avg_tensorrt\n    percentage_faster = (speedup_factor - 1) * 100\n\n    print(f\"Comparison (Batch Size {batch_size}, Precision {precision}):\")\n    print(f\"Average PyTorch Inference Time: {avg_pytorch:.4f} s\")\n    print(f\"Average TensorRT Inference Time: {avg_tensorrt:.4f} s\")\n    print(f\"TensorRT is {speedup_factor:.2f}x faster than PyTorch.\")\n    print(f\"TensorRT is {percentage_faster:.2f}% faster than PyTorch.\")\n    print()\n\ndef run_experiment(batch_size, precision, img_size, engine, context):\n    print(f\"Running experiment with batch size: {batch_size}, precision: {precision}, image size: {img_size}\")\n\n    # Load images\n    image_folder = \"/kaggle/input/dataset/images\"\n    images = load_images_from_folder(image_folder)\n\n    # Set up GPU memory for input and output\n    input_shape = context.get_binding_shape(0)\n\n    # Create CUDA stream\n    stream = cuda.Stream()\n\n    # Load PyTorch model\n    pytorch_model = torch.hub.load('pytorch/vision', 'resnet50', pretrained=True).eval().cuda()\n\n    # Benchmark PyTorch model\n    print(\"Running benchmark for PyTorch ResNet50 model...\")\n    total_time_pytorch, inference_times_pytorch = benchmark_pytorch_model(pytorch_model, images, preprocess_image, batch_size, img_size)\n\n    # Benchmark TensorRT model\n    print(\"Running benchmark for TensorRT ResNet50 model...\")\n    total_time_trt, inference_times_trt = benchmark_tensorrt_model(context, engine, images, None, stream, input_shape, preprocess_image, batch_size, img_size)\n\n    # Print statistics\n    print_inference_stats(inference_times_pytorch, f\"PyTorch (Batch {batch_size}, {img_size[0]}x{img_size[1]})\")\n    print_inference_stats(inference_times_trt, f\"TensorRT (Batch {batch_size}, {precision}, {img_size[0]}x{img_size[1]})\")\n\n    # Compare results\n    compare_models(inference_times_pytorch, inference_times_trt, precision, batch_size)\n\nif __name__ == '__main__':\n    # Build or load TensorRT engine\n    onnx_file_path = \"/kaggle/working/resnet50.onnx\"\n    engine_file_path = \"resnet50.engine\"\n    \n    if not os.path.exists(engine_file_path):\n        print(f\"Building engine from {onnx_file_path}...\")\n        build_engine_from_onnx(onnx_file_path, engine_file_path, max_batch_size=32, precision='FP16', img_size=(224, 224))\n        build_engine_from_onnx(onnx_file_path, engine_file_path.replace(\".engine\", \"_INT8.engine\"), max_batch_size=32, precision='INT8', img_size=(224, 224))\n    \n    # Load TensorRT engines\n    engine_fp16 = load_engine(engine_file_path)\n    engine_int8 = load_engine(engine_file_path.replace(\".engine\", \".engine\"))\n\n    context_fp16 = engine_fp16.create_execution_context()\n    context_int8 = engine_int8.create_execution_context()\n\n    # Experiment with different configurations\n    batch_sizes = [8, 16, 32]\n    for batch_size in batch_sizes:\n        run_experiment(batch_size, 'FP16', (224, 224), engine_fp16, context_fp16)\n        run_experiment(batch_size, 'INT8', (224, 224), engine_int8, context_int8)\n\n    nvmlShutdown()  # Clean up NVML\n","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:55:08.425246Z","iopub.execute_input":"2024-10-03T13:55:08.425655Z","iopub.status.idle":"2024-10-03T13:55:18.811136Z","shell.execute_reply.started":"2024-10-03T13:55:08.425616Z","shell.execute_reply":"2024-10-03T13:55:18.810092Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"[10/03/2024-13:55:08] [TRT] [W] TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.4.0\n[10/03/2024-13:55:08] [TRT] [W] TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.4.0\n[10/03/2024-13:55:08] [TRT] [W] TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.4.0\nRunning experiment with batch size: 8, precision: FP16, image size: (224, 224)\n[10/03/2024-13:55:08] [TRT] [W] TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.4.0\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/pytorch_vision_main\n","output_type":"stream"},{"name":"stdout","text":"Running benchmark for PyTorch ResNet50 model...\nBatch 1, Inference time (PyTorch): 0.0377 s, GPU used: 3311.88 MB\nBatch 2, Inference time (PyTorch): 0.0377 s, GPU used: 3311.88 MB\nBatch 3, Inference time (PyTorch): 0.0377 s, GPU used: 3311.88 MB\nBatch 4, Inference time (PyTorch): 0.0303 s, GPU used: 3311.88 MB\nBatch 5, Inference time (PyTorch): 0.0285 s, GPU used: 3311.88 MB\nBatch 6, Inference time (PyTorch): 0.0282 s, GPU used: 3311.88 MB\nBatch 7, Inference time (PyTorch): 0.0279 s, GPU used: 3311.88 MB\nBatch 8, Inference time (PyTorch): 0.0254 s, GPU used: 3311.88 MB\nBatch 9, Inference time (PyTorch): 0.0224 s, GPU used: 3311.88 MB\nBatch 10, Inference time (PyTorch): 0.0226 s, GPU used: 3311.88 MB\nBatch 11, Inference time (PyTorch): 0.0225 s, GPU used: 3311.88 MB\nBatch 12, Inference time (PyTorch): 0.0225 s, GPU used: 3311.88 MB\nBatch 13, Inference time (PyTorch): 0.0119 s, GPU used: 3311.88 MB\nRunning benchmark for TensorRT ResNet50 model...\n[10/03/2024-13:55:10] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 1, Inference time (TensorRT): 0.0032 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:10] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 2, Inference time (TensorRT): 0.0029 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:10] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 3, Inference time (TensorRT): 0.0029 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:10] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 4, Inference time (TensorRT): 0.0028 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:10] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 5, Inference time (TensorRT): 0.0028 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:10] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 6, Inference time (TensorRT): 0.0028 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:10] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 7, Inference time (TensorRT): 0.0029 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:10] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 8, Inference time (TensorRT): 0.0028 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:10] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 9, Inference time (TensorRT): 0.0028 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:10] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 10, Inference time (TensorRT): 0.0028 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:10] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 11, Inference time (TensorRT): 0.0028 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:10] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 12, Inference time (TensorRT): 0.0031 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:10] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 13, Inference time (TensorRT): 0.0029 s, GPU used: 3315.88 MB\n--- PyTorch (Batch 8, 224x224) Inference Time Statistics ---\nAverage Inference Time: 0.0273 s\nStandard Deviation: 0.0075 s\nMin Inference Time: 0.0119 s\nMax Inference Time: 0.0377 s\n\n--- TensorRT (Batch 8, FP16, 224x224) Inference Time Statistics ---\nAverage Inference Time: 0.0029 s\nStandard Deviation: 0.0001 s\nMin Inference Time: 0.0028 s\nMax Inference Time: 0.0032 s\n\nComparison (Batch Size 8, Precision FP16):\nAverage PyTorch Inference Time: 0.0273 s\nAverage TensorRT Inference Time: 0.0029 s\nTensorRT is 9.44x faster than PyTorch.\nTensorRT is 843.67% faster than PyTorch.\n\nRunning experiment with batch size: 8, precision: INT8, image size: (224, 224)\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/pytorch_vision_main\n","output_type":"stream"},{"name":"stdout","text":"Running benchmark for PyTorch ResNet50 model...\nBatch 1, Inference time (PyTorch): 0.0215 s, GPU used: 3311.88 MB\nBatch 2, Inference time (PyTorch): 0.0222 s, GPU used: 3311.88 MB\nBatch 3, Inference time (PyTorch): 0.0227 s, GPU used: 3311.88 MB\nBatch 4, Inference time (PyTorch): 0.0222 s, GPU used: 3311.88 MB\nBatch 5, Inference time (PyTorch): 0.0226 s, GPU used: 3311.88 MB\nBatch 6, Inference time (PyTorch): 0.0227 s, GPU used: 3311.88 MB\nBatch 7, Inference time (PyTorch): 0.0224 s, GPU used: 3311.88 MB\nBatch 8, Inference time (PyTorch): 0.0224 s, GPU used: 3311.88 MB\nBatch 9, Inference time (PyTorch): 0.0223 s, GPU used: 3311.88 MB\nBatch 10, Inference time (PyTorch): 0.0223 s, GPU used: 3311.88 MB\nBatch 11, Inference time (PyTorch): 0.0225 s, GPU used: 3311.88 MB\nBatch 12, Inference time (PyTorch): 0.0224 s, GPU used: 3311.88 MB\nBatch 13, Inference time (PyTorch): 0.0124 s, GPU used: 3311.88 MB\nRunning benchmark for TensorRT ResNet50 model...\n[10/03/2024-13:55:12] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 1, Inference time (TensorRT): 0.0033 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:12] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 2, Inference time (TensorRT): 0.0029 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:12] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 3, Inference time (TensorRT): 0.0029 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:12] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 4, Inference time (TensorRT): 0.0029 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:12] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 5, Inference time (TensorRT): 0.0029 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:12] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 6, Inference time (TensorRT): 0.0029 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:12] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 7, Inference time (TensorRT): 0.0029 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:12] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 8, Inference time (TensorRT): 0.0032 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:12] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 9, Inference time (TensorRT): 0.0029 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:12] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 10, Inference time (TensorRT): 0.0029 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:12] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 11, Inference time (TensorRT): 0.0029 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:12] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 12, Inference time (TensorRT): 0.0029 s, GPU used: 3317.88 MB\n[10/03/2024-13:55:12] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [8,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 8.\n)\nBatch 13, Inference time (TensorRT): 0.0029 s, GPU used: 3315.88 MB\n--- PyTorch (Batch 8, 224x224) Inference Time Statistics ---\nAverage Inference Time: 0.0216 s\nStandard Deviation: 0.0028 s\nMin Inference Time: 0.0124 s\nMax Inference Time: 0.0227 s\n\n--- TensorRT (Batch 8, INT8, 224x224) Inference Time Statistics ---\nAverage Inference Time: 0.0029 s\nStandard Deviation: 0.0001 s\nMin Inference Time: 0.0029 s\nMax Inference Time: 0.0033 s\n\nComparison (Batch Size 8, Precision INT8):\nAverage PyTorch Inference Time: 0.0216 s\nAverage TensorRT Inference Time: 0.0029 s\nTensorRT is 7.39x faster than PyTorch.\nTensorRT is 639.00% faster than PyTorch.\n\nRunning experiment with batch size: 16, precision: FP16, image size: (224, 224)\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/pytorch_vision_main\n","output_type":"stream"},{"name":"stdout","text":"Running benchmark for PyTorch ResNet50 model...\nBatch 1, Inference time (PyTorch): 0.0389 s, GPU used: 3311.88 MB\nBatch 2, Inference time (PyTorch): 0.0391 s, GPU used: 3311.88 MB\nBatch 3, Inference time (PyTorch): 0.0394 s, GPU used: 3311.88 MB\nBatch 4, Inference time (PyTorch): 0.0393 s, GPU used: 3311.88 MB\nBatch 5, Inference time (PyTorch): 0.0388 s, GPU used: 3311.88 MB\nBatch 6, Inference time (PyTorch): 0.0401 s, GPU used: 3311.88 MB\nBatch 7, Inference time (PyTorch): 0.0140 s, GPU used: 3311.88 MB\nRunning benchmark for TensorRT ResNet50 model...\n[10/03/2024-13:55:13] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [16,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 16.\n)\nBatch 1, Inference time (TensorRT): 0.0030 s, GPU used: 3321.88 MB\n[10/03/2024-13:55:14] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [16,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 16.\n)\nBatch 2, Inference time (TensorRT): 0.0029 s, GPU used: 3321.88 MB\n[10/03/2024-13:55:14] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [16,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 16.\n)\nBatch 3, Inference time (TensorRT): 0.0029 s, GPU used: 3321.88 MB\n[10/03/2024-13:55:14] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [16,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 16.\n)\nBatch 4, Inference time (TensorRT): 0.0029 s, GPU used: 3321.88 MB\n[10/03/2024-13:55:14] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [16,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 16.\n)\nBatch 5, Inference time (TensorRT): 0.0029 s, GPU used: 3321.88 MB\n[10/03/2024-13:55:14] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [16,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 16.\n)\nBatch 6, Inference time (TensorRT): 0.0029 s, GPU used: 3321.88 MB\n[10/03/2024-13:55:14] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [16,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 16.\n)\nBatch 7, Inference time (TensorRT): 0.0029 s, GPU used: 3315.88 MB\n--- PyTorch (Batch 16, 224x224) Inference Time Statistics ---\nAverage Inference Time: 0.0357 s\nStandard Deviation: 0.0095 s\nMin Inference Time: 0.0140 s\nMax Inference Time: 0.0401 s\n\n--- TensorRT (Batch 16, FP16, 224x224) Inference Time Statistics ---\nAverage Inference Time: 0.0029 s\nStandard Deviation: 0.0001 s\nMin Inference Time: 0.0029 s\nMax Inference Time: 0.0030 s\n\nComparison (Batch Size 16, Precision FP16):\nAverage PyTorch Inference Time: 0.0357 s\nAverage TensorRT Inference Time: 0.0029 s\nTensorRT is 12.33x faster than PyTorch.\nTensorRT is 1133.43% faster than PyTorch.\n\nRunning experiment with batch size: 16, precision: INT8, image size: (224, 224)\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/pytorch_vision_main\n","output_type":"stream"},{"name":"stdout","text":"Running benchmark for PyTorch ResNet50 model...\nBatch 1, Inference time (PyTorch): 0.0384 s, GPU used: 3311.88 MB\nBatch 2, Inference time (PyTorch): 0.0399 s, GPU used: 3311.88 MB\nBatch 3, Inference time (PyTorch): 0.0400 s, GPU used: 3311.88 MB\nBatch 4, Inference time (PyTorch): 0.0396 s, GPU used: 3311.88 MB\nBatch 5, Inference time (PyTorch): 0.0393 s, GPU used: 3311.88 MB\nBatch 6, Inference time (PyTorch): 0.0386 s, GPU used: 3311.88 MB\nBatch 7, Inference time (PyTorch): 0.0137 s, GPU used: 3311.88 MB\nRunning benchmark for TensorRT ResNet50 model...\n[10/03/2024-13:55:15] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [16,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 16.\n)\nBatch 1, Inference time (TensorRT): 0.0030 s, GPU used: 3321.88 MB\n[10/03/2024-13:55:15] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [16,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 16.\n)\nBatch 2, Inference time (TensorRT): 0.0029 s, GPU used: 3321.88 MB\n[10/03/2024-13:55:15] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [16,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 16.\n)\nBatch 3, Inference time (TensorRT): 0.0029 s, GPU used: 3321.88 MB\n[10/03/2024-13:55:15] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [16,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 16.\n)\nBatch 4, Inference time (TensorRT): 0.0029 s, GPU used: 3321.88 MB\n[10/03/2024-13:55:15] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [16,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 16.\n)\nBatch 5, Inference time (TensorRT): 0.0029 s, GPU used: 3321.88 MB\n[10/03/2024-13:55:15] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [16,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 16.\n)\nBatch 6, Inference time (TensorRT): 0.0029 s, GPU used: 3321.88 MB\n[10/03/2024-13:55:15] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [16,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 16.\n)\nBatch 7, Inference time (TensorRT): 0.0029 s, GPU used: 3315.88 MB\n--- PyTorch (Batch 16, 224x224) Inference Time Statistics ---\nAverage Inference Time: 0.0356 s\nStandard Deviation: 0.0097 s\nMin Inference Time: 0.0137 s\nMax Inference Time: 0.0400 s\n\n--- TensorRT (Batch 16, INT8, 224x224) Inference Time Statistics ---\nAverage Inference Time: 0.0029 s\nStandard Deviation: 0.0000 s\nMin Inference Time: 0.0029 s\nMax Inference Time: 0.0030 s\n\nComparison (Batch Size 16, Precision INT8):\nAverage PyTorch Inference Time: 0.0356 s\nAverage TensorRT Inference Time: 0.0029 s\nTensorRT is 12.31x faster than PyTorch.\nTensorRT is 1131.35% faster than PyTorch.\n\nRunning experiment with batch size: 32, precision: FP16, image size: (224, 224)\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/pytorch_vision_main\n","output_type":"stream"},{"name":"stdout","text":"Running benchmark for PyTorch ResNet50 model...\nBatch 1, Inference time (PyTorch): 0.0827 s, GPU used: 3311.88 MB\nBatch 2, Inference time (PyTorch): 0.0823 s, GPU used: 3311.88 MB\nBatch 3, Inference time (PyTorch): 0.0822 s, GPU used: 3311.88 MB\nBatch 4, Inference time (PyTorch): 0.0151 s, GPU used: 3311.88 MB\nRunning benchmark for TensorRT ResNet50 model...\n[10/03/2024-13:55:17] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [32,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 32.\n)\nBatch 1, Inference time (TensorRT): 0.0029 s, GPU used: 3331.88 MB\n[10/03/2024-13:55:17] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [32,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 32.\n)\nBatch 2, Inference time (TensorRT): 0.0029 s, GPU used: 3331.88 MB\n[10/03/2024-13:55:17] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [32,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 32.\n)\nBatch 3, Inference time (TensorRT): 0.0029 s, GPU used: 3331.88 MB\n[10/03/2024-13:55:17] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [32,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 32.\n)\nBatch 4, Inference time (TensorRT): 0.0029 s, GPU used: 3315.88 MB\n--- PyTorch (Batch 32, 224x224) Inference Time Statistics ---\nAverage Inference Time: 0.0656 s\nStandard Deviation: 0.0337 s\nMin Inference Time: 0.0151 s\nMax Inference Time: 0.0827 s\n\n--- TensorRT (Batch 32, FP16, 224x224) Inference Time Statistics ---\nAverage Inference Time: 0.0029 s\nStandard Deviation: 0.0000 s\nMin Inference Time: 0.0029 s\nMax Inference Time: 0.0029 s\n\nComparison (Batch Size 32, Precision FP16):\nAverage PyTorch Inference Time: 0.0656 s\nAverage TensorRT Inference Time: 0.0029 s\nTensorRT is 22.73x faster than PyTorch.\nTensorRT is 2173.27% faster than PyTorch.\n\nRunning experiment with batch size: 32, precision: INT8, image size: (224, 224)\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/pytorch_vision_main\n","output_type":"stream"},{"name":"stdout","text":"Running benchmark for PyTorch ResNet50 model...\nBatch 1, Inference time (PyTorch): 0.0811 s, GPU used: 3311.88 MB\nBatch 2, Inference time (PyTorch): 0.0818 s, GPU used: 3311.88 MB\nBatch 3, Inference time (PyTorch): 0.0829 s, GPU used: 3311.88 MB\nBatch 4, Inference time (PyTorch): 0.0144 s, GPU used: 3311.88 MB\nRunning benchmark for TensorRT ResNet50 model...\n[10/03/2024-13:55:18] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [32,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 32.\n)\nBatch 1, Inference time (TensorRT): 0.0032 s, GPU used: 3331.88 MB\n[10/03/2024-13:55:18] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [32,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 32.\n)\nBatch 2, Inference time (TensorRT): 0.0032 s, GPU used: 3331.88 MB\n[10/03/2024-13:55:18] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [32,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 32.\n)\nBatch 3, Inference time (TensorRT): 0.0032 s, GPU used: 3331.88 MB\n[10/03/2024-13:55:18] [TRT] [E] 3: [executionContext.cpp::setBindingDimensions::976] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::setBindingDimensions::976, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [32,3,224,224] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 32.\n)\nBatch 4, Inference time (TensorRT): 0.0032 s, GPU used: 3315.88 MB\n--- PyTorch (Batch 32, 224x224) Inference Time Statistics ---\nAverage Inference Time: 0.0651 s\nStandard Deviation: 0.0338 s\nMin Inference Time: 0.0144 s\nMax Inference Time: 0.0829 s\n\n--- TensorRT (Batch 32, INT8, 224x224) Inference Time Statistics ---\nAverage Inference Time: 0.0032 s\nStandard Deviation: 0.0000 s\nMin Inference Time: 0.0032 s\nMax Inference Time: 0.0032 s\n\nComparison (Batch Size 32, Precision INT8):\nAverage PyTorch Inference Time: 0.0651 s\nAverage TensorRT Inference Time: 0.0032 s\nTensorRT is 20.44x faster than PyTorch.\nTensorRT is 1944.12% faster than PyTorch.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}